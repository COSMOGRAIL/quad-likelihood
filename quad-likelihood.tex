\documentclass[11pt]{scrartcl}

\usepackage{xspace}
\usepackage{color}
 
\newcommand{\com}[2]{\xspace\textcolor{red}{\textbf{Comment by #1: #2}}}


\newcommand{\dt}[1]{\ensuremath{\Delta t_{\mathrm{#1}}}\xspace}
%\newcommand{\truedt}{\ensuremath{\Delta t_{\mathrm{true}}}\xspace}
%\newcommand{\modeldt}{\ensuremath{\Delta t_{\mathrm{model}}}\xspace}
%\newcommand{\obsdt}{\ensuremath{\Delta t_{\mathrm{obs}}}\xspace}


\begin{document}

\title{Paragraph on how to express the likelihood of a model given COSMOGRAIL time-delay measurements for quad lenses}
\date{\today}
\maketitle


\section{The current state}

The current way of expressing COSMOGRAIL results for quads is to give 6 dependent -- and consistent -- time-delay estimations, without any estimates of the covariances between these 6 measurements\footnote{We only check visually that the correlations between residuals behave as expected.}. This is described in Section 3 of the PyCS paper. The motivation for giving 6 measurements is that we don't want to pick a priori one of the QSO-images as reference. Note that delivering these 6 \emph{dependent} estimates does contain part of the information that would otherwise go into a covariance matrix associated with giving only 3 ``independent'' delays such as AB, AC and AD. Indeed, a tight covariance between AB and AC (for example) would tell that the delay BC is well constrained. Currently, we just give this delay BC. When fitting a lens model, one currently selects a posteriori 3 ``independent'' delays with small error bars, and one would pick this BC. That's how it was done so far.

\section{The problem}

\begin{itemize}
\item Assuming that these 3 ``independent'' point and uncertainty estimates are truly independent is wrong (the true delays are, but not their measurements). 
\item Selecting the 3 delays among 6 is arbitrary
\item Using all 6 of them without taking into account their covariances is certainly wrong
\end{itemize}

And so it's not fully clear how to write a likelihood of lens model predictions, given COSMOGRAIL measurements.

\section{The fix (under construction)}

We want to propose (and give in our publications) a classical form of the likelihood to be used when modeling our measurements. If we assume that all errors are Gaussian, this would be

\begin{equation}
p(\dt{model} | \mathrm{obs}) = \frac{1}{(2 \pi)^{n/2} |\Sigma|^{1/2}}\exp\left( -\frac{1}{2} (\dt{model}-\dt{obs})^T\Sigma^{-1}(\dt{model}-\dt{obs}) \right)
\end{equation}

where $\Sigma \approx \textrm{Cov}(\dt{obs})$ is an estimation of the covariance that we would give.

\begin{itemize}
\item We \emph{think} that writing this using 3 delays such as (AB, AC, AD) is correct, and the associated 3x3 covariance matrix does in fact capture the full information contained in our measurements, \emph{even if the light curve of A is of poor quality and the choice of BA, BC, BD seems apparently ``better''}. The choice of A as a reference does not matter, as long as the 3x3 covariance matrix is given together with the 3 delay estimates. Test this ?
\item For 6 delays, the covariance matrix would be 6x6. But this matrix is clearly redundant (BC = AC - AB exactly, for every single measurement), while it can't encode this redundancy. Our feeling is that using it in the above equation is wrong and would result in an overly tight likelihood. If we want to use the 6x6 matrix nevertheless (because of our special conservative PyCS way of computing variances ignoring the true delays), can we modify the above equation to compensate for using redundant information ?

\end{itemize}

\end{document}

